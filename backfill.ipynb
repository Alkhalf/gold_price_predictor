{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binance.client import Client\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api_key = 'ZkndW133Kc7JBCDbVV5DV9TSkpkTAm93VaKOSygIDiKi6rOK9tKnOubD4gXY1SSs'\n",
    "api_secret = 'l3QgD9k6dXDcArEhzSnfXCVtpSykCilnPrk3Ol5xjbJuoH2XYfResrjuAeBHoJgZ'\n",
    "\n",
    "client = Client(api_key, api_secret)\n",
    "def convert_to_utc(timestamp_ms):\n",
    "    \"\"\"\n",
    "    Convert the timestamp in milliseconds to a UTC datetime object.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.utcfromtimestamp(timestamp_ms / 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_gold_prices(symbol=\"PAXGUSDT\", interval=Client.KLINE_INTERVAL_1HOUR, days=2):\n",
    "    \"\"\"\n",
    "    Retrieves hourly gold prices and returns them as a DataFrame.\n",
    "    \"\"\"\n",
    "    end_time = datetime.datetime.now().replace(minute=0, second=0, microsecond=0)  # Align to the last full hour\n",
    "    start_time = end_time - timedelta(days=days)\n",
    "    start_time_ms = int(start_time.timestamp() * 1000)\n",
    "    end_time_ms = int(end_time.timestamp() * 1000)\n",
    "\n",
    "    klines = client.get_historical_klines(symbol, interval, start_time_ms, end_time_ms)\n",
    "\n",
    "    df = pd.DataFrame(klines, columns=[\n",
    "        \"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"close_time\",\n",
    "        \"quote_asset_volume\", \"number_of_trades\", \"taker_buy_base_asset_volume\",\n",
    "        \"taker_buy_quote_asset_volume\", \"ignore\"\n",
    "    ])\n",
    "    \n",
    "    # Convert timestamps to UTC datetime\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(convert_to_utc)\n",
    "    \n",
    "    df = df[[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "    df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]] = df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]].apply(pd.to_numeric)\n",
    "    df.rename(columns={\"close\": \"gold_price\"}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_bitcoin_prices(symbol=\"BTCUSDT\", interval=Client.KLINE_INTERVAL_1HOUR, days=2):\n",
    "    \"\"\"\n",
    "    Retrieves hourly Bitcoin prices and returns them as a DataFrame.\n",
    "    \"\"\"\n",
    "    end_time = datetime.datetime.now().replace(minute=0, second=0, microsecond=0)  # Align to the last full hour\n",
    "    start_time = end_time - timedelta(days=days)\n",
    "    start_time_ms = int(start_time.timestamp() * 1000)\n",
    "    end_time_ms = int(end_time.timestamp() * 1000)\n",
    "\n",
    "    klines = client.get_historical_klines(symbol, interval, start_time_ms, end_time_ms)\n",
    "\n",
    "    df = pd.DataFrame(klines, columns=[\n",
    "        \"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"close_time\",\n",
    "        \"quote_asset_volume\", \"number_of_trades\", \"taker_buy_base_asset_volume\",\n",
    "        \"taker_buy_quote_asset_volume\", \"ignore\"\n",
    "    ])\n",
    "    \n",
    "    # Convert timestamps to UTC datetime\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(convert_to_utc)\n",
    "    \n",
    "    df = df[[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "    df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]] = df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]].apply(pd.to_numeric)\n",
    "    df.rename(columns={\"close\": \"bitcoin_price\"}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_utc(timestamp_ms):\n",
    "    \"\"\"\n",
    "    Convert the timestamp in milliseconds to a UTC datetime object.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.utcfromtimestamp(timestamp_ms / 1000)\n",
    "\n",
    "def get_hourly_data_from_binance(symbol='EURUSDT', interval='1h', days=1):\n",
    "    \"\"\"\n",
    "    Retrieves historical hourly data for a symbol from Binance, handling pagination in 20-day chunks.\n",
    "    \"\"\"\n",
    "    # Calculate the end time and the start time based on the number of days\n",
    "    end_time = datetime.datetime.now().replace(minute=0, second=0, microsecond=0)\n",
    "    start_time = end_time - timedelta(days=days)\n",
    "    \n",
    "    start_time_ms = int(start_time.timestamp() * 1000)\n",
    "    end_time_ms = int(end_time.timestamp() * 1000)\n",
    "    \n",
    "    max_range = 1000  # Binance allows a max of 1000 points per request\n",
    "\n",
    "    all_hourly_data = []\n",
    "\n",
    "    # Split the data retrieval into 20-day chunks\n",
    "    chunk_size = 20  # We fetch 20 days of data at a time\n",
    "    for i in range(0, days, chunk_size):\n",
    "        chunk_start_time = start_time + timedelta(days=i)\n",
    "        chunk_end_time = min(start_time + timedelta(days=(i + chunk_size)), end_time)\n",
    "        \n",
    "        chunk_start_time_ms = int(chunk_start_time.timestamp() * 1000)\n",
    "        chunk_end_time_ms = int(chunk_end_time.timestamp() * 1000)\n",
    "        \n",
    "        # Binance API endpoint for historical klines (candlestick data)\n",
    "        url = f\"https://api.binance.com/api/v3/klines\"\n",
    "        params = {\n",
    "            'symbol': symbol,\n",
    "            'interval': interval,\n",
    "            'startTime': chunk_start_time_ms,\n",
    "            'endTime': chunk_end_time_ms,\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Convert the timestamps to UTC datetime\n",
    "            hourly_data = [(convert_to_utc(item[0]), float(item[4])) for item in data]  # Add price as the 5th column\n",
    "            all_hourly_data.extend(hourly_data)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            break\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_hourly_data, columns=[\"timestamp\", \"price\"])\n",
    "    df.set_index(\"timestamp\", inplace=True)\n",
    "    \n",
    "    # Drop any overlapping rows (the first row after each chunk could be a duplicate)\n",
    "    df = df.loc[~df.index.duplicated(keep='first')]  # Remove duplicates\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_hourly_inflation(symbol='EURUSDT', days=1, interval='1h'):\n",
    "    \"\"\"\n",
    "    Calculates the hourly inflation rates based on hourly exchange rates.\n",
    "    \"\"\"\n",
    "    # Fetch hourly data\n",
    "    df = get_hourly_data_from_binance(symbol, interval, days)\n",
    "    \n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "\n",
    "    # Calculate inflation rates\n",
    "    hourly_inflation = []\n",
    "    for i in range(1, len(df)):\n",
    "        current_time = df.index[i]\n",
    "        current_rate = df.iloc[i][\"price\"]\n",
    "        previous_rate = df.iloc[i - 1][\"price\"]\n",
    "\n",
    "        if previous_rate > 0:\n",
    "            inflation_rate = ((current_rate - previous_rate) / previous_rate) * 100\n",
    "            hourly_inflation.append((current_time, current_rate, inflation_rate))  # Add both price and inflation rate\n",
    "\n",
    "    # Create a DataFrame for inflation rates and prices\n",
    "    inflation_df = pd.DataFrame(hourly_inflation, columns=[\"timestamp\", \"price\", \"inflation_rate\"])\n",
    "    \n",
    "    # Ensure the timestamp is a regular column (not index)\n",
    "    inflation_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return inflation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch data\n",
    "days=365\n",
    "gold_prices = get_hourly_gold_prices(days=days)\n",
    "gold_prices.to_csv(\"gold_hourly_prices.csv\", index=False)\n",
    "\n",
    "# bitcoin_prices = get_hourly_bitcoin_prices(days=days)\n",
    "# bitcoin_prices.to_csv(\"bitcoin_hourly_prices.csv\", index=False)\n",
    "\n",
    "inflation_data = calculate_hourly_inflation(symbol='EURUSDT', days=days)\n",
    "inflation_data.to_csv(\"hourly_exchange_rates.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation_file = 'hourly_exchange_rates.csv'\n",
    "gold_prices_file = 'gold_hourly_prices.csv'\n",
    "bitcoin_file = 'bitcoin_hourly_prices.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp   price  inflation_rate\n",
      "0  2024-01-06 14:00:00  1.0883        0.027574\n",
      "1  2024-01-06 15:00:00  1.0881       -0.018377\n",
      "2  2024-01-06 16:00:00  1.0881        0.000000\n",
      "3  2024-01-06 17:00:00  1.0886        0.045952\n",
      "4  2024-01-06 18:00:00  1.0889        0.027558\n"
     ]
    }
   ],
   "source": [
    "df_inflation = pd.read_csv(inflation_file)\n",
    "print(df_inflation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp    open    high     low  gold_price    volume\n",
      "0  2024-01-06 13:00:00  2018.0  2019.0  2016.0      2019.0   14.1820\n",
      "1  2024-01-06 14:00:00  2018.0  2022.0  2018.0      2021.0    6.8325\n",
      "2  2024-01-06 15:00:00  2021.0  2022.0  2004.0      2015.0  188.4057\n",
      "3  2024-01-06 16:00:00  2015.0  2021.0  2014.0      2016.0   27.5479\n",
      "4  2024-01-06 17:00:00  2017.0  2020.0  2016.0      2017.0    4.6245\n"
     ]
    }
   ],
   "source": [
    "df_gold_prices = pd.read_csv(gold_prices_file)\n",
    "print(df_gold_prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  inflation_rate    open    high     low  gold_price  \\\n",
      "0  2024-01-06 14:00:00        0.027574  2018.0  2022.0  2018.0      2021.0   \n",
      "1  2024-01-06 15:00:00       -0.018377  2021.0  2022.0  2004.0      2015.0   \n",
      "2  2024-01-06 16:00:00        0.000000  2015.0  2021.0  2014.0      2016.0   \n",
      "3  2024-01-06 17:00:00        0.045952  2017.0  2020.0  2016.0      2017.0   \n",
      "4  2024-01-06 18:00:00        0.027558  2017.0  2017.0  2015.0      2016.0   \n",
      "\n",
      "     volume  \n",
      "0    6.8325  \n",
      "1  188.4057  \n",
      "2   27.5479  \n",
      "3    4.6245  \n",
      "4    4.4821  \n"
     ]
    }
   ],
   "source": [
    "final_df = pd.merge(df_inflation, df_gold_prices, on='timestamp', how='inner')\n",
    "final_df  = pd.DataFrame(final_df)\n",
    "final_df.drop(columns='price', inplace=True)\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  inflation_rate    open    high     low  gold_price  \\\n",
      "1  2024-01-06 15:00:00        0.027574  2018.0  2022.0  2018.0      2015.0   \n",
      "2  2024-01-06 16:00:00       -0.018377  2021.0  2022.0  2004.0      2016.0   \n",
      "3  2024-01-06 17:00:00        0.000000  2015.0  2021.0  2014.0      2017.0   \n",
      "4  2024-01-06 18:00:00        0.045952  2017.0  2020.0  2016.0      2016.0   \n",
      "5  2024-01-06 19:00:00        0.027558  2017.0  2017.0  2015.0      2013.0   \n",
      "\n",
      "     volume  \n",
      "1    6.8325  \n",
      "2  188.4057  \n",
      "3   27.5479  \n",
      "4    4.6245  \n",
      "5    4.4821  \n"
     ]
    }
   ],
   "source": [
    "shifted_c = ['inflation_rate', 'open', 'high', 'low', 'volume']\n",
    "final_df[shifted_c] = final_df[shifted_c].shift(1)\n",
    "final_df.dropna(inplace=True)\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-05 14:35:48,338 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-01-05 14:35:48,342 INFO: Initializing external client\n",
      "2025-01-05 14:35:48,342 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-05 14:35:49,688 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1168537\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HOPSWORKS_API_KEY\"] = \"WMg6iOTOV75YfUcb.AcuNGWjcMS79s4bz0FqZsRaJtcU8Siqu7Mx084dfkRHauMxK251VTYLYSBAIqBb5\"\n",
    "project = hopsworks.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_historic = fs.get_or_create_feature_group(\n",
    "    name='data_historic',\n",
    "    description='historic data all features',\n",
    "    version=1,\n",
    "    primary_key=['timestamp'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1168537/fs/1159240/fg/1394572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 8759/8759 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: data_historic_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1168537/jobs/named/data_historic_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('data_historic_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_historic.insert(final_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
